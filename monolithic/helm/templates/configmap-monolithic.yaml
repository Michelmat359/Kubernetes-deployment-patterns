apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "ros2-monolithic.fullname" . }}-code
  labels:
    {{- include "ros2-monolithic.labels" . | nindent 4 }}
data:
  monolithic.py: |
    import os, time, threading, rclpy
    from rclpy.node import Node
    from std_msgs.msg import String
    from prometheus_client import start_http_server, Gauge

    LATENCY = Gauge('ros2_latency_seconds', 'End-to-end latency in seconds')

    def start_talker(message_rate):
        class Talker(Node):
            def __init__(self):
                super().__init__('bench_talker')
                self.pub = self.create_publisher(String, 'chatter', 10)
                self.timer = self.create_timer(1.0 / message_rate, self.tick)
            def tick(self):
                ts = time.time()
                msg = String()
                msg.data = str(ts)
                self.pub.publish(msg)

        rclpy.init()
        node = Talker()
        rclpy.spin(node)

    def start_listener():
        class Listener(Node):
            def __init__(self):
                super().__init__('bench_listener')
                self.sub = self.create_subscription(String, 'chatter', self.cb, 10)
            def cb(self, msg):
                recv_ts = time.time()
                send_ts = float(msg.data)
                LATENCY.observe(recv_ts - send_ts)

        rclpy.init()
        node = Listener()
        rclpy.spin(node)

    def main():
        rate = float(os.getenv('MESSAGE_RATE', '10'))
        start_http_server(int(os.getenv('METRICS_PORT', '9090')))
        # Ejecutar talker y listener en hilos separados
        t1 = threading.Thread(target=lambda: start_talker(rate), daemon=True)
        t2 = threading.Thread(target=start_listener, daemon=True)
        t1.start()
        t2.start()
        t1.join()
        t2.join()

    if __name__ == '__main__':
        main()